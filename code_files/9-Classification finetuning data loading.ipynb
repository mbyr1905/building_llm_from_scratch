{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINETUNING FOR CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOWNLOADING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\sms_spam_collection\\SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import ssl\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"../sms_spam_collection.zip\"\n",
    "extracted_path = \"../sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Create an unverified SSL context\n",
    "    ssl_context = ssl._create_unverified_context()\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url, context=ssl_context) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    \n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    \n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    \n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "This process is similar to converting text into token IDs. \n",
    "\n",
    "However, instead of using the GPT\n",
    "vocabulary, which consists of more than 50,000 words, we are dealing with just two token\n",
    "IDs: 0 and 1.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045\n",
      "149\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "print(len(train_df))\n",
    "print(len(validation_df))\n",
    "print(len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"../sms_spam_collection/train.csv\", index=None)\n",
    "validation_df.to_csv(\"../sms_spam_collection/validation.csv\", index=None)\n",
    "test_df.to_csv(\"../sms_spam_collection/test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        \n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"../sms_spam_collection/train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"../sms_spam_collection/validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "print(val_dataset.max_length)\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"../sms_spam_collection/test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "print(test_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INITIALIZING A MODEL WITH PRETRAINED WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn   \n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)#true-> bassesl correction\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),#expansion as expanded params are sent to GeLU \n",
    "            GELU(),# activation step\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),#Compression of previous expansaion\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out#6 as same as d_in\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim(3)\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        #b- batch size, num_tokens - number of tokens in that batch(3), d_in - input dim of each token(Here we took it to be 6)\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"], \n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x\n",
    "    \n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "        \n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        \n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]  \n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "    \n",
    "import numpy as np\n",
    "\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\building_llm_from_scratch\\building_llm_from_scratch\\llm_venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: ../gpt2\\124M\\checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\building_llm_from_scratch\\building_llm_from_scratch\\llm_venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: ../gpt2\\124M\\encoder.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\building_llm_from_scratch\\building_llm_from_scratch\\llm_venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: ../gpt2\\124M\\hparams.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\building_llm_from_scratch\\building_llm_from_scratch\\llm_venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: ../gpt2\\124M\\model.ckpt.data-00000-of-00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\building_llm_from_scratch\\building_llm_from_scratch\\llm_venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: ../gpt2\\124M\\model.ckpt.index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\building_llm_from_scratch\\building_llm_from_scratch\\llm_venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: ../gpt2\\124M\\model.ckpt.meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\building_llm_from_scratch\\building_llm_from_scratch\\llm_venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: ../gpt2\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "\n",
    "from gpt_download3 import download_and_load_gpt2\n",
    "\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"../gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADDING A CLASSIFICATION HEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CALCULATING THE CLASSIFICATION LOSS AND ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as in chapter 5\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.453\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINETUNING THE MODEL ON SUPERVISED DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Step 1: Set model to training mode\n",
    "\n",
    "Step 2: Reset loss gradients from previous batch iteration\n",
    "\n",
    "Step 3: Calculate loss gradients\n",
    "\n",
    "Step 4: Update model weights using loss gradients\n",
    "\n",
    "Step 5: New: track examples instead of tokens\n",
    "\n",
    "Step 6: Optional evaluation step\n",
    "\n",
    "Step 7: Calculate accuracy after each epoch\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall the same as `train_model_simple` in chapter 5\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as chapter 5\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.392\n",
      "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
      "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
      "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
      "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
      "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
      "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
      "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
      "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.320\n",
      "Ep 3 (Step 000350): Train loss 0.340, Val loss 0.306\n",
      "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
      "Ep 4 (Step 000400): Train loss 0.136, Val loss 0.200\n",
      "Ep 4 (Step 000450): Train loss 0.153, Val loss 0.132\n",
      "Ep 4 (Step 000500): Train loss 0.222, Val loss 0.137\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.207, Val loss 0.143\n",
      "Ep 5 (Step 000600): Train loss 0.083, Val loss 0.074\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 67.38 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 97.21%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 95.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USING THE LLM AS A SPAM CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
    "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
    "\n",
    "    # Truncate sequences if they too long\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Return the classified result\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../models/review_classifier.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"../models/review_classifier.pth\")\n",
    "model.load_state_dict(model_state_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
